{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PkHUghnrcYcu"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from konlpy.tag import Komoran\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Je-XzHPiSzu"
   },
   "source": [
    "## 1. 'ì˜¤ëŠ˜' update ëœ ê³µì§€ë§Œ í¬ë¡¤ë§ í•´ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mPjvdH-nGJ5B",
    "outputId": "dcfd7d16-7a59-4e80-b1bf-e5ef9b1d9003"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì œëª©: [í•´ì €ë“œë¦¬í„°ëŸ¬ì‹œìœµí•©êµìœ¡ ì—°êµ¬ì†Œ] ê³„ì•½ì§ì› ì±„ìš© ê³µê³ , ë“±ë¡ì¼: 2024-09-26\n",
      "ì œëª©: [ì…í•™] 2025í•™ë…„ë„ ì „ê¸° ê³µì—°ì˜ˆìˆ ëŒ€í•™ì›(ì•¼ê°„) ì‹ ì…ìƒ ëª¨ì§‘(10/10~10/24), ë“±ë¡ì¼: 2024-09-26\n",
      "ì œëª©: [ì±„ìš©]ì´í™”ì—¬ìëŒ€í•™êµ í•™êµí­ë ¥ì˜ˆë°©ì—°êµ¬ì†Œ ì—°êµ¬ì› ëª¨ì§‘ ê³µê³ , ë“±ë¡ì¼: 2024-09-26\n",
      "ì œëª©: [ê±´ì¶•íŒ€] ê³µì‚¬ë¡œ ì¸í•œ í†µí–‰ì œí•œ ì•ˆë‚´ (9/29 ì¼ ~ 9/30 ì›”), ë“±ë¡ì¼: 2024-09-26\n",
      "ì œëª©: ë””ìì¸ì”½í‚¹ ì›Œí¬ìˆ : ì°½ì˜ì  í•´ê²°ë²•ì„ ì°¾ì•„ê°€ëŠ” ê³¼ì •ë³„ ë°©ë²•ë¡  íŠ¹ê°• (íœ´í•™ìƒ ê°€ëŠ¥), ë“±ë¡ì¼: 2024-09-26\n",
      "ì œëª©: [ì±„ìš©] ì‚¬ë²”ëŒ€í•™ ê³¼í•™êµìœ¡ê³¼ í•™ê³¼ì‚¬ë¬´ì‹¤ ê³„ì•½ì§ì› ì±„ìš© ê³µê³ , ë“±ë¡ì¼: 2024-09-26\n",
      "ì œëª©: [ì¸ì¬] 2024ë…„ë„ 5ê¸‰(í–‰ì •) ë° ì™¸êµê´€í›„ë³´ìì„ ë°œì‹œí—˜ 3ì°¨ ëŒ€ë¹„ í”„ë¡œê·¸ë¨ ì•ˆë‚´(2ì°¨ í•©ê²©ì ëŒ€ìƒ), ë“±ë¡ì¼: 2024-09-26\n",
      "ì œëª©: [ì¡°êµëª¨ì§‘] ë²•ì „ì› ì¡¸ì—…ì‹œí—˜ ê°ë…ì¡°êµ ëª¨ì§‘ (~10/7), ë“±ë¡ì¼: 2024-09-26\n"
     ]
    }
   ],
   "source": [
    "# User-Agent í—¤ë” ì„¤ì •\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/98.0.4758.102\"}\n",
    "\n",
    "def fetch_notices():\n",
    "    notices = []\n",
    "    offset = 0\n",
    "    today = datetime.today().strftime('%Y-%m-%d')\n",
    "    more_pages = True\n",
    "\n",
    "    while more_pages:\n",
    "        # ê³µì§€ì‚¬í•­ ëª©ë¡ í˜ì´ì§€ URL (í˜ì´ì§€ ë„˜ë²„ë§ ì ìš©)\n",
    "        url = f\"https://ewha.ac.kr/ewha/news/notice.do?mode=list&&articleLimit=10&article.offset={offset}\"\n",
    "\n",
    "        # í˜ì´ì§€ ê°€ì ¸ì˜¤ê¸°\n",
    "        response = requests.get(url, headers=headers)\n",
    "        html = response.text\n",
    "\n",
    "        # BeautifulSoupì„ ì‚¬ìš©í•˜ì—¬ HTML íŒŒì‹±\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        # ê³µì§€ì‚¬í•­ í–‰ ì¶”ì¶œ\n",
    "        page_notices = soup.find_all('tr')\n",
    "\n",
    "        # ê³ ì •ëœ ê³µì§€ì‚¬í•­ì€ ê°€ì ¸ì˜¤ì§€ ë§ê³ , ì¼ë°˜ ê³µì§€ì‚¬í•­ë§Œ ê°€ì ¸ì˜´\n",
    "        for notice in page_notices:\n",
    "            # ê³ ì •ëœ ê³µì§€ëŠ” <tr class=\"b top box\">ê°€ ìˆìŒ\n",
    "            if 'b-top-box' in notice.get('class', []):\n",
    "                continue\n",
    "\n",
    "            # ì¼ë°˜ ê³µì§€ëŠ” í´ë˜ìŠ¤ê°€ ì—†ëŠ” <tr> íƒœê·¸ë¥¼ ì‚¬ìš©\n",
    "            num_box = notice.find('td', class_='b-num-box')\n",
    "\n",
    "            if num_box:  # ì¼ë°˜ ê³µì§€ì¼ ë•Œë§Œ ì²˜ë¦¬\n",
    "                title = notice.find('td', class_='b-td-left').find('div', class_='b-title-box').find('a').get_text(strip=True)\n",
    "                date = notice.find('span', class_='b-date').get_text(strip=True)\n",
    "                date = date.replace('.', '-')\n",
    "\n",
    "                # ë§Œì•½ ì˜¤ëŠ˜ì˜ ë‚ ì§œê°€ ì•„ë‹ˆë©´ ë” ì´ìƒ í¬ë¡¤ë§í•˜ì§€ ì•ŠìŒ\n",
    "                if date != today:\n",
    "                    more_pages = False\n",
    "                    break  # í˜„ì¬ í˜ì´ì§€ì˜ ë‚˜ë¨¸ì§€ë„ ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ\n",
    "\n",
    "                # ì˜¤ëŠ˜ ë‚ ì§œì˜ ê³µì§€ë§Œ ì €ì¥\n",
    "                notices.append({'title': title, 'date': date})\n",
    "\n",
    "        if more_pages:\n",
    "            offset += 10  # ì˜¤ëŠ˜ ë‚ ì§œì¸ ê³µì§€ê°€ ìˆì„ ê²½ìš°ì—ë§Œ ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™\n",
    "\n",
    "    return notices\n",
    "\n",
    "# ê³µì§€ì‚¬í•­ ê°€ì ¸ì˜¤ê¸°\n",
    "all_notices = fetch_notices()\n",
    "\n",
    "# ê°€ì ¸ì˜¨ ê³µì§€ì‚¬í•­ ì¶œë ¥\n",
    "for notice in all_notices:\n",
    "    print(f\"ì œëª©: {notice['title']}, ë“±ë¡ì¼: {notice['date']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NxOSaKKD5Nrq",
    "outputId": "17779490-8d83-4d0f-d00d-46ebbe948533"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[í•´ì €ë“œë¦¬í„°ëŸ¬ì‹œìœµí•©êµìœ¡ ì—°êµ¬ì†Œ] ê³„ì•½ì§ì› ì±„ìš© ê³µê³ ', '[ì…í•™] 2025í•™ë…„ë„ ì „ê¸° ê³µì—°ì˜ˆìˆ ëŒ€í•™ì›(ì•¼ê°„) ì‹ ì…ìƒ ëª¨ì§‘(10/10~10/24)', '[ì±„ìš©]ì´í™”ì—¬ìëŒ€í•™êµ í•™êµí­ë ¥ì˜ˆë°©ì—°êµ¬ì†Œ ì—°êµ¬ì› ëª¨ì§‘ ê³µê³ ', '[ê±´ì¶•íŒ€] ê³µì‚¬ë¡œ ì¸í•œ í†µí–‰ì œí•œ ì•ˆë‚´ (9/29 ì¼ ~ 9/30 ì›”)', 'ë””ìì¸ì”½í‚¹ ì›Œí¬ìˆ : ì°½ì˜ì  í•´ê²°ë²•ì„ ì°¾ì•„ê°€ëŠ” ê³¼ì •ë³„ ë°©ë²•ë¡  íŠ¹ê°• (íœ´í•™ìƒ ê°€ëŠ¥)', '[ì±„ìš©] ì‚¬ë²”ëŒ€í•™ ê³¼í•™êµìœ¡ê³¼ í•™ê³¼ì‚¬ë¬´ì‹¤ ê³„ì•½ì§ì› ì±„ìš© ê³µê³ ', '[ì¸ì¬] 2024ë…„ë„ 5ê¸‰(í–‰ì •) ë° ì™¸êµê´€í›„ë³´ìì„ ë°œì‹œí—˜ 3ì°¨ ëŒ€ë¹„ í”„ë¡œê·¸ë¨ ì•ˆë‚´(2ì°¨ í•©ê²©ì ëŒ€ìƒ)', '[ì¡°êµëª¨ì§‘] ë²•ì „ì› ì¡¸ì—…ì‹œí—˜ ê°ë…ì¡°êµ ëª¨ì§‘ (~10/7)']\n"
     ]
    }
   ],
   "source": [
    "# 'date' í•„ë“œë¥¼ ì œê±°í•œ ìƒˆë¡œìš´ ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "all_notices= [notice['title'] for notice in all_notices]\n",
    "\n",
    "print(all_notices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ICQD2gCp6Cdr",
    "outputId": "38feb734-9d08-42b3-beda-27346dd88e0c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[í•´ì €ë“œë¦¬í„°ëŸ¬ì‹œìœµí•©êµìœ¡ ì—°êµ¬ì†Œ] ê³„ì•½ì§ì› ì±„ìš© ê³µê³ </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ì…í•™] 2025í•™ë…„ë„ ì „ê¸° ê³µì—°ì˜ˆìˆ ëŒ€í•™ì›(ì•¼ê°„) ì‹ ì…ìƒ ëª¨ì§‘(10/10~10/24)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ì±„ìš©]ì´í™”ì—¬ìëŒ€í•™êµ í•™êµí­ë ¥ì˜ˆë°©ì—°êµ¬ì†Œ ì—°êµ¬ì› ëª¨ì§‘ ê³µê³ </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ê±´ì¶•íŒ€] ê³µì‚¬ë¡œ ì¸í•œ í†µí–‰ì œí•œ ì•ˆë‚´ (9/29 ì¼ ~ 9/30 ì›”)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ë””ìì¸ì”½í‚¹ ì›Œí¬ìˆ : ì°½ì˜ì  í•´ê²°ë²•ì„ ì°¾ì•„ê°€ëŠ” ê³¼ì •ë³„ ë°©ë²•ë¡  íŠ¹ê°• (íœ´í•™ìƒ ê°€ëŠ¥)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             title\n",
       "0                     [í•´ì €ë“œë¦¬í„°ëŸ¬ì‹œìœµí•©êµìœ¡ ì—°êµ¬ì†Œ] ê³„ì•½ì§ì› ì±„ìš© ê³µê³ \n",
       "1  [ì…í•™] 2025í•™ë…„ë„ ì „ê¸° ê³µì—°ì˜ˆìˆ ëŒ€í•™ì›(ì•¼ê°„) ì‹ ì…ìƒ ëª¨ì§‘(10/10~10/24)\n",
       "2                  [ì±„ìš©]ì´í™”ì—¬ìëŒ€í•™êµ í•™êµí­ë ¥ì˜ˆë°©ì—°êµ¬ì†Œ ì—°êµ¬ì› ëª¨ì§‘ ê³µê³ \n",
       "3           [ê±´ì¶•íŒ€] ê³µì‚¬ë¡œ ì¸í•œ í†µí–‰ì œí•œ ì•ˆë‚´ (9/29 ì¼ ~ 9/30 ì›”)\n",
       "4    ë””ìì¸ì”½í‚¹ ì›Œí¬ìˆ : ì°½ì˜ì  í•´ê²°ë²•ì„ ì°¾ì•„ê°€ëŠ” ê³¼ì •ë³„ ë°©ë²•ë¡  íŠ¹ê°• (íœ´í•™ìƒ ê°€ëŠ¥)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ê²°ê³¼ë¥¼ pandas ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜\n",
    "df = pd.DataFrame(all_notices, columns=['title'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aUCa5EwsG1bg"
   },
   "source": [
    "## 2. ì „ì²˜ë¦¬ ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ì˜ë¬¸ìì™€ í•œê¸€ë§Œ titleì— ë‚¨ê¸°ê¸°\n",
    "\n",
    "df1['title'] = df1['title'].str.replace('[^a-z|A-Z|ã„±-ã…|ê°€-í£|]', ' ', regex = True)\n",
    "\n",
    "# lambda í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ì„œ textì˜ íƒì§€ëœ xë¥¼ lowercaseë¡œ ë°”ê¿”ì¤€ë‹¤.\n",
    "def lowercase(text):\n",
    "    return re.sub(r'[a-zA-Z]', lambda x: x.group().lower(), text)\n",
    "\n",
    "df1['title'] = df1['title'].apply(lowercase)\n",
    "\n",
    "# ì˜ì–´ì™€ í•œêµ­ì–´ê°€ ì„ì—¬ ìˆìœ¼ë¯€ë¡œ êµ¬ë¶„í•  ìˆ˜ ìˆë„ë¡\n",
    "eng = re.compile(r'[a-zA-Z]')\n",
    "    \n",
    "#ë¶ˆìš©ì–´ ì‚¬ì „\n",
    "stop_words = ['ì˜','ê°€','ì´','ì€','ë“¤','ëŠ”','ê±','ê³¼','ë“¤','ê³¼','ìœ¼ë¡œ','ë„','ì„',\n",
    "              'ë¥¼','ìœ¼ë¡œ','ì','ì—','ì™€','í•œ','í•˜ë‹¤','ì—ì„œ','ì—ê²Œ', 'ë°', 'ì—°ë„', 'ë…„',\n",
    "              'ë…„ë„', 'í•™ê¸°', 'ã„´' 'í•™ë…„ë„', 'íšŒ', 'ìƒë°˜ê¸°', 'í•˜ë°˜ê¸°', 'ë…„ëŒ€', 'í•™ë…„',\n",
    "              'ì˜¤í›„', 'ì˜¤ì „', 'ì˜¤ëŠ˜', 'ë‚´ì¼', 'íšŒì°¨', 'ê°œì›”', 'ì£¼ë…„', 'ì¢…ë£Œ', 'th', 'st', 'nd', \"'s\", 'ì ‘ìˆ˜', 'ê¸°í•œ', 'ì—°ì¥',\n",
    "              'ì›”', 'ì–´', 'ë‹¤', 'ê¹Œì§€', 'ì œ', 'ë“±', 'ë“±ë“±', 'ëª‡', 'ë©´', 'ê°', 'ê°ê°', 'ë§ˆê°','ê³µí†µ', 'ë§Œë£Œ',\n",
    "              'ì—¬', 'ëŒ€', 'ë°±ì–‘']\n",
    "\n",
    "# í˜•íƒœì†Œ ë¶„ì„ ë° ë¶ˆìš©ì–´ ì œê±° í•¨ìˆ˜\n",
    "\n",
    "def preprocess(text):\n",
    "    komoran = Komoran(userdic = '/content/drive/MyDrive/á„‹á…²á„…á…¥á†« 24 á„‹á…§á„…á…³á†· á„‡á…¡á†¼á„’á…¡á†¨ á„‘á…³á„…á…©á„Œá…¦á†¨á„á…³/eda&á„Œá…¥á†«á„á…¥á„…á…µ/user_dictionary.txt')\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    token_list = []\n",
    "\n",
    "    for sentence in text :\n",
    "       sentence = sentence.strip()\n",
    "       if not sentence:\n",
    "           token_list.append('')\n",
    "           continue\n",
    "\n",
    "       words = sentence.split()\n",
    "       sentense_list = []\n",
    "\n",
    "       for word in words :\n",
    "          if eng.match(word) :\n",
    "              tokens_word = word_tokenize(word)\n",
    "              tokens_pos = pos_tag(tokens_word)\n",
    "              for w, pos in tokens_pos:\n",
    "                  if pos.startswith('N'):\n",
    "                      lemma = lemmatizer.lemmatize(w, pos='n')\n",
    "                  elif pos.startswith('V'):\n",
    "                      lemma = lemmatizer.lemmatize(w, pos='v')\n",
    "                  elif pos.startswith('J'):\n",
    "                      lemma = lemmatizer.lemmatize(w, pos='a')\n",
    "                  elif pos.startswith('R'):\n",
    "                      lemma = lemmatizer.lemmatize(w, pos='r')\n",
    "                  else :\n",
    "                      continue\n",
    "                  sentense_list.append(lemma)\n",
    "\n",
    "          else :\n",
    "              nouns = komoran.nouns(word)\n",
    "              sentense_list.extend(nouns)\n",
    "       token = [t for t in sentense_list if t not in stop_words]\n",
    "       token_list.append(' '.join(token))\n",
    "    return token_list\n",
    "\n",
    "df1['processed_title'] = preprocess(df1['title'])\n",
    "\n",
    "# í•œ ê¸€ì ë‹¨ì–´ë¥¼ ì œê±°í•˜ë˜ \"íŒ€\"ê³¼ \"ë©\" ë‹¨ì–´ëŠ” ìœ ì§€í•˜ëŠ” í•¨ìˆ˜\n",
    "\n",
    "def remove_single_characters(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if len(word) > 1 or word in ['íŒ€', 'ë©']]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "df1['processed_title'] = df1['processed_title'].apply(remove_single_characters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[í•´ì €ë“œë¦¬í„°ëŸ¬ì‹œìœµí•©êµìœ¡ ì—°êµ¬ì†Œ] ê³„ì•½ì§ì› ì±„ìš© ê³µê³ </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ì…í•™] 2025í•™ë…„ë„ ì „ê¸° ê³µì—°ì˜ˆìˆ ëŒ€í•™ì›(ì•¼ê°„) ì‹ ì…ìƒ ëª¨ì§‘(10/10~10/24)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ì±„ìš©]ì´í™”ì—¬ìëŒ€í•™êµ í•™êµí­ë ¥ì˜ˆë°©ì—°êµ¬ì†Œ ì—°êµ¬ì› ëª¨ì§‘ ê³µê³ </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ê±´ì¶•íŒ€] ê³µì‚¬ë¡œ ì¸í•œ í†µí–‰ì œí•œ ì•ˆë‚´ (9/29 ì¼ ~ 9/30 ì›”)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ë””ìì¸ì”½í‚¹ ì›Œí¬ìˆ : ì°½ì˜ì  í•´ê²°ë²•ì„ ì°¾ì•„ê°€ëŠ” ê³¼ì •ë³„ ë°©ë²•ë¡  íŠ¹ê°• (íœ´í•™ìƒ ê°€ëŠ¥)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[ì±„ìš©] ì‚¬ë²”ëŒ€í•™ ê³¼í•™êµìœ¡ê³¼ í•™ê³¼ì‚¬ë¬´ì‹¤ ê³„ì•½ì§ì› ì±„ìš© ê³µê³ </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[ì¸ì¬] 2024ë…„ë„ 5ê¸‰(í–‰ì •) ë° ì™¸êµê´€í›„ë³´ìì„ ë°œì‹œí—˜ 3ì°¨ ëŒ€ë¹„ í”„ë¡œê·¸ë¨ ì•ˆë‚´(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[ì¡°êµëª¨ì§‘] ë²•ì „ì› ì¡¸ì—…ì‹œí—˜ ê°ë…ì¡°êµ ëª¨ì§‘ (~10/7)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title\n",
       "0                       [í•´ì €ë“œë¦¬í„°ëŸ¬ì‹œìœµí•©êµìœ¡ ì—°êµ¬ì†Œ] ê³„ì•½ì§ì› ì±„ìš© ê³µê³ \n",
       "1    [ì…í•™] 2025í•™ë…„ë„ ì „ê¸° ê³µì—°ì˜ˆìˆ ëŒ€í•™ì›(ì•¼ê°„) ì‹ ì…ìƒ ëª¨ì§‘(10/10~10/24)\n",
       "2                    [ì±„ìš©]ì´í™”ì—¬ìëŒ€í•™êµ í•™êµí­ë ¥ì˜ˆë°©ì—°êµ¬ì†Œ ì—°êµ¬ì› ëª¨ì§‘ ê³µê³ \n",
       "3             [ê±´ì¶•íŒ€] ê³µì‚¬ë¡œ ì¸í•œ í†µí–‰ì œí•œ ì•ˆë‚´ (9/29 ì¼ ~ 9/30 ì›”)\n",
       "4      ë””ìì¸ì”½í‚¹ ì›Œí¬ìˆ : ì°½ì˜ì  í•´ê²°ë²•ì„ ì°¾ì•„ê°€ëŠ” ê³¼ì •ë³„ ë°©ë²•ë¡  íŠ¹ê°• (íœ´í•™ìƒ ê°€ëŠ¥)\n",
       "5                   [ì±„ìš©] ì‚¬ë²”ëŒ€í•™ ê³¼í•™êµìœ¡ê³¼ í•™ê³¼ì‚¬ë¬´ì‹¤ ê³„ì•½ì§ì› ì±„ìš© ê³µê³ \n",
       "6  [ì¸ì¬] 2024ë…„ë„ 5ê¸‰(í–‰ì •) ë° ì™¸êµê´€í›„ë³´ìì„ ë°œì‹œí—˜ 3ì°¨ ëŒ€ë¹„ í”„ë¡œê·¸ë¨ ì•ˆë‚´(...\n",
       "7                    [ì¡°êµëª¨ì§‘] ë²•ì „ì› ì¡¸ì—…ì‹œí—˜ ê°ë…ì¡°êµ ëª¨ì§‘ (~10/7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>processed_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>í•´ì €ë“œë¦¬í„°ëŸ¬ì‹œìœµí•©êµìœ¡ ì—°êµ¬ì†Œ  ê³„ì•½ì§ì› ì±„ìš© ê³µê³ </td>\n",
       "      <td>í•´ì €ë“œ ë¦¬í„° ëŸ¬ì‹œ ìœµí•© êµìœ¡ ì—°êµ¬ì†Œ ê³„ì•½ ì§ì› ì±„ìš© ê³µê³ </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ì…í•™      í•™ë…„ë„ ì „ê¸° ê³µì—°ì˜ˆìˆ ëŒ€í•™ì› ì•¼ê°„  ì‹ ì…ìƒ ëª¨ì§‘</td>\n",
       "      <td>ì…í•™ ì „ê¸° ê³µì—° ì˜ˆìˆ  ëŒ€í•™ì› ì•¼ê°„ ì‹ ì…ìƒ ëª¨ì§‘</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ì±„ìš© ì´í™”ì—¬ìëŒ€í•™êµ í•™êµí­ë ¥ì˜ˆë°©ì—°êµ¬ì†Œ ì—°êµ¬ì› ëª¨ì§‘ ê³µê³ </td>\n",
       "      <td>ì±„ìš© ì´í™”ì—¬ìëŒ€í•™êµ í•™êµ í­ë ¥ ì˜ˆë°© ì—°êµ¬ì†Œ ì—°êµ¬ì› ëª¨ì§‘ ê³µê³ </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ê±´ì¶•íŒ€  ê³µì‚¬ë¡œ ì¸í•œ í†µí–‰ì œí•œ ì•ˆë‚´       ì¼        ì›”</td>\n",
       "      <td>ê±´ì¶• íŒ€ ê³µì‚¬ í†µí–‰ ì œí•œ ì•ˆë‚´</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ë””ìì¸ì”½í‚¹ ì›Œí¬ìˆ   ì°½ì˜ì  í•´ê²°ë²•ì„ ì°¾ì•„ê°€ëŠ” ê³¼ì •ë³„ ë°©ë²•ë¡  íŠ¹ê°•  íœ´í•™ìƒ ê°€ëŠ¥</td>\n",
       "      <td>ì›Œí¬ìˆ ì°½ì˜ í•´ê²° ê³¼ì • ë°©ë²•ë¡  íŠ¹ê°• íœ´í•™</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ì±„ìš©  ì‚¬ë²”ëŒ€í•™ ê³¼í•™êµìœ¡ê³¼ í•™ê³¼ì‚¬ë¬´ì‹¤ ê³„ì•½ì§ì› ì±„ìš© ê³µê³ </td>\n",
       "      <td>ì±„ìš© ì‚¬ë²”ëŒ€í•™ ê³¼í•™ êµìœ¡ í•™ê³¼ ì‚¬ë¬´ì‹¤ ê³„ì•½ ì§ì› ì±„ìš© ê³µê³ </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ì¸ì¬      ë…„ë„  ê¸‰ í–‰ì •  ë° ì™¸êµê´€í›„ë³´ìì„ ë°œì‹œí—˜  ì°¨ ëŒ€ë¹„ í”„ë¡œê·¸ë¨ ì•ˆë‚´ ...</td>\n",
       "      <td>ì¸ì¬ í–‰ì • ì™¸êµê´€ í›„ë³´ì ì„ ë°œ ì‹œí—˜ ëŒ€ë¹„ í”„ë¡œê·¸ë¨ ì•ˆë‚´ í•©ê²©ì ëŒ€ìƒ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ì¡°êµëª¨ì§‘  ë²•ì „ì› ì¡¸ì—…ì‹œí—˜ ê°ë…ì¡°êµ ëª¨ì§‘</td>\n",
       "      <td>ì¡°êµ ëª¨ì§‘ ì „ì› ì¡¸ì—… ì‹œí—˜ ê°ë… ì¡°êµ ëª¨ì§‘</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                        í•´ì €ë“œë¦¬í„°ëŸ¬ì‹œìœµí•©êµìœ¡ ì—°êµ¬ì†Œ  ê³„ì•½ì§ì› ì±„ìš© ê³µê³    \n",
       "1     ì…í•™      í•™ë…„ë„ ì „ê¸° ê³µì—°ì˜ˆìˆ ëŒ€í•™ì› ì•¼ê°„  ì‹ ì…ìƒ ëª¨ì§‘                \n",
       "2                     ì±„ìš© ì´í™”ì—¬ìëŒ€í•™êµ í•™êµí­ë ¥ì˜ˆë°©ì—°êµ¬ì†Œ ì—°êµ¬ì› ëª¨ì§‘ ê³µê³    \n",
       "3              ê±´ì¶•íŒ€  ê³µì‚¬ë¡œ ì¸í•œ í†µí–‰ì œí•œ ì•ˆë‚´       ì¼        ì›”    \n",
       "4      ë””ìì¸ì”½í‚¹ ì›Œí¬ìˆ   ì°½ì˜ì  í•´ê²°ë²•ì„ ì°¾ì•„ê°€ëŠ” ê³¼ì •ë³„ ë°©ë²•ë¡  íŠ¹ê°•  íœ´í•™ìƒ ê°€ëŠ¥    \n",
       "5                    ì±„ìš©  ì‚¬ë²”ëŒ€í•™ ê³¼í•™êµìœ¡ê³¼ í•™ê³¼ì‚¬ë¬´ì‹¤ ê³„ì•½ì§ì› ì±„ìš© ê³µê³    \n",
       "6   ì¸ì¬      ë…„ë„  ê¸‰ í–‰ì •  ë° ì™¸êµê´€í›„ë³´ìì„ ë°œì‹œí—˜  ì°¨ ëŒ€ë¹„ í”„ë¡œê·¸ë¨ ì•ˆë‚´ ...   \n",
       "7                     ì¡°êµëª¨ì§‘  ë²•ì „ì› ì¡¸ì—…ì‹œí—˜ ê°ë…ì¡°êµ ëª¨ì§‘           \n",
       "\n",
       "                         processed_title  \n",
       "0        í•´ì €ë“œ ë¦¬í„° ëŸ¬ì‹œ ìœµí•© êµìœ¡ ì—°êµ¬ì†Œ ê³„ì•½ ì§ì› ì±„ìš© ê³µê³   \n",
       "1              ì…í•™ ì „ê¸° ê³µì—° ì˜ˆìˆ  ëŒ€í•™ì› ì•¼ê°„ ì‹ ì…ìƒ ëª¨ì§‘  \n",
       "2      ì±„ìš© ì´í™”ì—¬ìëŒ€í•™êµ í•™êµ í­ë ¥ ì˜ˆë°© ì—°êµ¬ì†Œ ì—°êµ¬ì› ëª¨ì§‘ ê³µê³   \n",
       "3                       ê±´ì¶• íŒ€ ê³µì‚¬ í†µí–‰ ì œí•œ ì•ˆë‚´  \n",
       "4                 ì›Œí¬ìˆ ì°½ì˜ í•´ê²° ê³¼ì • ë°©ë²•ë¡  íŠ¹ê°• íœ´í•™  \n",
       "5       ì±„ìš© ì‚¬ë²”ëŒ€í•™ ê³¼í•™ êµìœ¡ í•™ê³¼ ì‚¬ë¬´ì‹¤ ê³„ì•½ ì§ì› ì±„ìš© ê³µê³   \n",
       "6  ì¸ì¬ í–‰ì • ì™¸êµê´€ í›„ë³´ì ì„ ë°œ ì‹œí—˜ ëŒ€ë¹„ í”„ë¡œê·¸ë¨ ì•ˆë‚´ í•©ê²©ì ëŒ€ìƒ  \n",
       "7                ì¡°êµ ëª¨ì§‘ ì „ì› ì¡¸ì—… ì‹œí—˜ ê°ë… ì¡°êµ ëª¨ì§‘  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. NLP ëª¨ë¸ë¡œ ì»¤ë¦¬ì–´ ê´€ë ¨ ê³µì§€ ë¶„ë¥˜í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abeek' 'abeek ì—°êµ¬ì›' 'abeek ìì²´' ... 'í¬ë§ ì²­ë…„' 'í¬ë§ì' 'í¬ë§ì ëª¨ì§‘']\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Flex\\anaconda3\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator CountVectorizer from version 1.5.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# N-ê·¸ë¨ ë²¡í„°í™” (1-ê·¸ë¨, 2-ê·¸ë¨)\n",
    "vectorizer = joblib.load(\"C:/Users/Flex/Documents/Euron 6th/ngram_vectorizer.pkl\")\n",
    "X_ngrams = vectorizer.transform(df1['processed_title']).toarray()\n",
    "\n",
    "print(vectorizer.get_feature_names_out())\n",
    "print(X_ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'KoBertTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n",
      "C:\\Users\\Flex\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(8002, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KoBERT ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "tokenizer = BertTokenizer.from_pretrained('monologg/kobert')\n",
    "model = BertModel.from_pretrained('monologg/kobert')\n",
    "\n",
    "# GPU ì„¤ì •\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¬¸ì¥ ì„ë² ë”© ì¶”ì¶œ\n",
    "def get_sentence_embedding(sentence):\n",
    "    inputs = tokenizer(sentence, return_tensors='pt', truncation=True, padding=True, max_length=128)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}  # ë°ì´í„°ë¥¼ GPUë¡œ ì´ë™\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # ê²°ê³¼ë¥¼ CPUë¡œ ë‹¤ì‹œ ì´ë™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë“  ë¬¸ì¥ì— ëŒ€í•´ ì„ë² ë”© ì¶”ì¶œ\n",
    "embeddings = [get_sentence_embedding(sentence) for sentence in df1['processed_title']]\n",
    "X_embeddings = pd.DataFrame(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_combined = np.hstack((X_ngrams, X_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Flex\\anaconda3\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator LogisticRegression from version 1.5.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ML model load\n",
    "LR = joblib.load(\"C:/Users/Flex/Documents/Euron 6th/logistic_regression_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = LR.predict(X_combined)\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>processed_title</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>í•´ì €ë“œë¦¬í„°ëŸ¬ì‹œìœµí•©êµìœ¡ ì—°êµ¬ì†Œ  ê³„ì•½ì§ì› ì±„ìš© ê³µê³ </td>\n",
       "      <td>í•´ì €ë“œ ë¦¬í„° ëŸ¬ì‹œ ìœµí•© êµìœ¡ ì—°êµ¬ì†Œ ê³„ì•½ ì§ì› ì±„ìš© ê³µê³ </td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ì…í•™      í•™ë…„ë„ ì „ê¸° ê³µì—°ì˜ˆìˆ ëŒ€í•™ì› ì•¼ê°„  ì‹ ì…ìƒ ëª¨ì§‘</td>\n",
       "      <td>ì…í•™ ì „ê¸° ê³µì—° ì˜ˆìˆ  ëŒ€í•™ì› ì•¼ê°„ ì‹ ì…ìƒ ëª¨ì§‘</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ì±„ìš© ì´í™”ì—¬ìëŒ€í•™êµ í•™êµí­ë ¥ì˜ˆë°©ì—°êµ¬ì†Œ ì—°êµ¬ì› ëª¨ì§‘ ê³µê³ </td>\n",
       "      <td>ì±„ìš© ì´í™”ì—¬ìëŒ€í•™êµ í•™êµ í­ë ¥ ì˜ˆë°© ì—°êµ¬ì†Œ ì—°êµ¬ì› ëª¨ì§‘ ê³µê³ </td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ê±´ì¶•íŒ€  ê³µì‚¬ë¡œ ì¸í•œ í†µí–‰ì œí•œ ì•ˆë‚´       ì¼        ì›”</td>\n",
       "      <td>ê±´ì¶• íŒ€ ê³µì‚¬ í†µí–‰ ì œí•œ ì•ˆë‚´</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ë””ìì¸ì”½í‚¹ ì›Œí¬ìˆ   ì°½ì˜ì  í•´ê²°ë²•ì„ ì°¾ì•„ê°€ëŠ” ê³¼ì •ë³„ ë°©ë²•ë¡  íŠ¹ê°•  íœ´í•™ìƒ ê°€ëŠ¥</td>\n",
       "      <td>ì›Œí¬ìˆ ì°½ì˜ í•´ê²° ê³¼ì • ë°©ë²•ë¡  íŠ¹ê°• íœ´í•™</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ì±„ìš©  ì‚¬ë²”ëŒ€í•™ ê³¼í•™êµìœ¡ê³¼ í•™ê³¼ì‚¬ë¬´ì‹¤ ê³„ì•½ì§ì› ì±„ìš© ê³µê³ </td>\n",
       "      <td>ì±„ìš© ì‚¬ë²”ëŒ€í•™ ê³¼í•™ êµìœ¡ í•™ê³¼ ì‚¬ë¬´ì‹¤ ê³„ì•½ ì§ì› ì±„ìš© ê³µê³ </td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ì¸ì¬      ë…„ë„  ê¸‰ í–‰ì •  ë° ì™¸êµê´€í›„ë³´ìì„ ë°œì‹œí—˜  ì°¨ ëŒ€ë¹„ í”„ë¡œê·¸ë¨ ì•ˆë‚´ ...</td>\n",
       "      <td>ì¸ì¬ í–‰ì • ì™¸êµê´€ í›„ë³´ì ì„ ë°œ ì‹œí—˜ ëŒ€ë¹„ í”„ë¡œê·¸ë¨ ì•ˆë‚´ í•©ê²©ì ëŒ€ìƒ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ì¡°êµëª¨ì§‘  ë²•ì „ì› ì¡¸ì—…ì‹œí—˜ ê°ë…ì¡°êµ ëª¨ì§‘</td>\n",
       "      <td>ì¡°êµ ëª¨ì§‘ ì „ì› ì¡¸ì—… ì‹œí—˜ ê°ë… ì¡°êµ ëª¨ì§‘</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                        í•´ì €ë“œë¦¬í„°ëŸ¬ì‹œìœµí•©êµìœ¡ ì—°êµ¬ì†Œ  ê³„ì•½ì§ì› ì±„ìš© ê³µê³    \n",
       "1     ì…í•™      í•™ë…„ë„ ì „ê¸° ê³µì—°ì˜ˆìˆ ëŒ€í•™ì› ì•¼ê°„  ì‹ ì…ìƒ ëª¨ì§‘                \n",
       "2                     ì±„ìš© ì´í™”ì—¬ìëŒ€í•™êµ í•™êµí­ë ¥ì˜ˆë°©ì—°êµ¬ì†Œ ì—°êµ¬ì› ëª¨ì§‘ ê³µê³    \n",
       "3              ê±´ì¶•íŒ€  ê³µì‚¬ë¡œ ì¸í•œ í†µí–‰ì œí•œ ì•ˆë‚´       ì¼        ì›”    \n",
       "4      ë””ìì¸ì”½í‚¹ ì›Œí¬ìˆ   ì°½ì˜ì  í•´ê²°ë²•ì„ ì°¾ì•„ê°€ëŠ” ê³¼ì •ë³„ ë°©ë²•ë¡  íŠ¹ê°•  íœ´í•™ìƒ ê°€ëŠ¥    \n",
       "5                    ì±„ìš©  ì‚¬ë²”ëŒ€í•™ ê³¼í•™êµìœ¡ê³¼ í•™ê³¼ì‚¬ë¬´ì‹¤ ê³„ì•½ì§ì› ì±„ìš© ê³µê³    \n",
       "6   ì¸ì¬      ë…„ë„  ê¸‰ í–‰ì •  ë° ì™¸êµê´€í›„ë³´ìì„ ë°œì‹œí—˜  ì°¨ ëŒ€ë¹„ í”„ë¡œê·¸ë¨ ì•ˆë‚´ ...   \n",
       "7                     ì¡°êµëª¨ì§‘  ë²•ì „ì› ì¡¸ì—…ì‹œí—˜ ê°ë…ì¡°êµ ëª¨ì§‘           \n",
       "\n",
       "                         processed_title  label  \n",
       "0        í•´ì €ë“œ ë¦¬í„° ëŸ¬ì‹œ ìœµí•© êµìœ¡ ì—°êµ¬ì†Œ ê³„ì•½ ì§ì› ì±„ìš© ê³µê³       1  \n",
       "1              ì…í•™ ì „ê¸° ê³µì—° ì˜ˆìˆ  ëŒ€í•™ì› ì•¼ê°„ ì‹ ì…ìƒ ëª¨ì§‘      0  \n",
       "2      ì±„ìš© ì´í™”ì—¬ìëŒ€í•™êµ í•™êµ í­ë ¥ ì˜ˆë°© ì—°êµ¬ì†Œ ì—°êµ¬ì› ëª¨ì§‘ ê³µê³       1  \n",
       "3                       ê±´ì¶• íŒ€ ê³µì‚¬ í†µí–‰ ì œí•œ ì•ˆë‚´      0  \n",
       "4                 ì›Œí¬ìˆ ì°½ì˜ í•´ê²° ê³¼ì • ë°©ë²•ë¡  íŠ¹ê°• íœ´í•™      1  \n",
       "5       ì±„ìš© ì‚¬ë²”ëŒ€í•™ ê³¼í•™ êµìœ¡ í•™ê³¼ ì‚¬ë¬´ì‹¤ ê³„ì•½ ì§ì› ì±„ìš© ê³µê³       1  \n",
       "6  ì¸ì¬ í–‰ì • ì™¸êµê´€ í›„ë³´ì ì„ ë°œ ì‹œí—˜ ëŒ€ë¹„ í”„ë¡œê·¸ë¨ ì•ˆë‚´ í•©ê²©ì ëŒ€ìƒ      1  \n",
       "7                ì¡°êµ ëª¨ì§‘ ì „ì› ì¡¸ì—… ì‹œí—˜ ê°ë… ì¡°êµ ëª¨ì§‘      0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['label'] = y_pred\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 'label'ì´ 1ì¸ í–‰ë“¤ì˜ ì¸ë±ìŠ¤ ì¶”ì¶œ\n",
    "indices = df1[df1['label'] == 1].index\n",
    "\n",
    "# í•´ë‹¹ ì¸ë±ìŠ¤ì˜ 'title' ì—´ ê°’ ê°€ì ¸ì˜¤ê¸°\n",
    "career_notices = df.loc[indices, 'title']\n",
    "\n",
    "def organize_title(notices):\n",
    "    if notices is None or len(notices) == 0:  \n",
    "        return \"ì˜¤ëŠ˜ì€ ì»¤ë¦¬ì–´ ê´€ë ¨ ê³µì§€ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "    \n",
    "    # ê³µì§€ì‚¬í•­ì´ ìˆì„ ë•Œ ë¬¸ìì—´ ìƒì„±\n",
    "    organized_list = '\\n'.join([f\"ğŸ”¸ {title}\" for title in notices])\n",
    "    return organized_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gsQYqiaYHFuA"
   },
   "source": [
    "## 4. ì´ë©”ì¼ë¡œ ì•Œë¦¼ ë³´ë‚´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Jupyter Notebookì—ì„œ í™˜ê²½ ë³€ìˆ˜ ì„¤ì •\n",
    "os.environ['EMAIL_PASSWORD'] = 'ryot gxkt zhyb hbwn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "R_R68UbCHKA6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "ì´ë©”ì¼ ì „ì†¡ ì„±ê³µ!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "\n",
    "def send_email(subject, body, to_email):\n",
    "    from_email = \"eunbin3660@gmail.com\"\n",
    "    password = os.getenv('EMAIL_PASSWORD')  # ì•± ë¹„ë°€ë²ˆí˜¸ë¥¼ í™˜ê²½ ë³€ìˆ˜ë¡œ ì²˜ë¦¬\n",
    "\n",
    "    # ì´ë©”ì¼ ë©”ì‹œì§€ ìƒì„±\n",
    "    msg = MIMEText(body)\n",
    "    msg['Subject'] = subject\n",
    "    msg['From'] = from_email\n",
    "    msg['To'] = to_email\n",
    "\n",
    "    try:\n",
    "        # Gmail SMTP ì„œë²„ì— ì—°ê²°\n",
    "        server = smtplib.SMTP_SSL('smtp.gmail.com', 465)\n",
    "        server.login(from_email, password)\n",
    "        server.sendmail(from_email, to_email, msg.as_string())\n",
    "        server.quit()\n",
    "        print(\"ì´ë©”ì¼ ì „ì†¡ ì„±ê³µ!\")\n",
    "    except smtplib.SMTPAuthenticationError as e:\n",
    "        print(f\"SMTP ì¸ì¦ ì˜¤ë¥˜: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"ì´ë©”ì¼ ì „ì†¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "\n",
    "# ì»¤ë¦¬ì–´ ê´€ë ¨ ê³µì§€ê°€ ìˆë‹¤ë©´ ì´ë©”ì¼ë¡œ ë³´ë‚´ê¸°\n",
    "if not career_notices.empty:\n",
    "    subject = \"ì˜¤ëŠ˜ì˜ ì»¤ë¦¬ì–´ ê´€ë ¨ ê³µì§€ì‚¬í•­\"\n",
    "    body = organize_title(career_notices)\n",
    "    send_email(subject, body, \"eunbin3660@gmail.com\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "3g-tobM8HJ8Y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(os.getenv('EMAIL_PASSWORD'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
